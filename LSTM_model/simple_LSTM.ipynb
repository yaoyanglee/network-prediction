{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scapy.all import rdpcap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset creation\n",
    "N = 100 # Num of training samples\n",
    "L = 1000 # Length of past window\n",
    "T = 20\n",
    "\n",
    "x = np.empty((N, L), np.float32)\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4*T, 4*T, N).reshape(N, 1)\n",
    "y = np.sin(x/1.0/T).astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, n_hidden=51):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        # Defining 2 LSTMS stacked on top of each other\n",
    "        self.lstm1 = nn.LSTMCell(1, self.n_hidden) \n",
    "        self.lstm2 = nn.LSTMCell(self.n_hidden, self.n_hidden)\n",
    "        self.linear = nn.Linear(self.n_hidden, 1)\n",
    "\n",
    "    def forward(self, input, prediction_window=0):\n",
    "        outputs = []\n",
    "        n_samples = input.size(0)\n",
    "\n",
    "        # Initializing the hidden states and cell states\n",
    "        h_t = torch.zeros(n_samples, self.n_hidden, dtype=torch.float32)\n",
    "        c_t = torch.zeros(n_samples, self.n_hidden, dtype=torch.float32)\n",
    "        h_t2 = torch.zeros(n_samples, self.n_hidden, dtype=torch.float32)\n",
    "        c_t2 = torch.zeros(n_samples, self.n_hidden, dtype=torch.float32)\n",
    "\n",
    "        # Split input tensor into chunks of size, 1, row-wise\n",
    "        for input_t in input.split(1, dim=1):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs.append(output)\n",
    "            \n",
    "        for i in range(prediction_window):\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs.append(output)\n",
    "\n",
    "        # Concatentating all outputs, history + future, row-wise\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "# Initializing training inputs and targest\n",
    "# We are simply setting the test as the 1 step ground truth. \n",
    "# From the 3rd batch to the 100th batch. From the first element to just before the last element\n",
    "train_input = torch.from_numpy(y[3:, :-1])\n",
    "# From the 3rd batch to the 100th batch. From the second element to the last element\n",
    "train_target = torch.from_numpy(y[3:, 1:])\n",
    "\n",
    "# From the 3rd batch to the 100th batch. From the first element to just before the last element\n",
    "test_input = torch.from_numpy(y[:3, :-1])\n",
    "# From the 3rd batch to the 100th batch. From the second element to the last element\n",
    "test_target = torch.from_numpy(y[:3, 1:])\n",
    "\n",
    "# Initialising model, loss and optimizer\n",
    "model = LSTMPredictor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0\n",
      "loss:  0.5228500366210938\n",
      "loss:  0.5132181644439697\n",
      "loss:  0.4854382872581482\n",
      "loss:  0.4666913151741028\n",
      "loss:  0.38999059796333313\n",
      "loss:  1.3184086084365845\n",
      "loss:  0.22002696990966797\n",
      "loss:  0.12816883623600006\n",
      "loss:  0.07541168481111526\n",
      "loss:  0.03319218382239342\n",
      "loss:  0.03266485407948494\n",
      "loss:  0.03157762065529823\n",
      "loss:  0.03027687966823578\n",
      "loss:  0.02739923819899559\n",
      "loss:  0.022314928472042084\n",
      "loss:  0.013450122438371181\n",
      "loss:  0.008019685745239258\n",
      "loss:  0.007019301410764456\n",
      "loss:  0.004727658815681934\n",
      "loss:  0.002284238813444972\n",
      "Test Loss:  0.0013238618848845363\n",
      "n:  999\n",
      "Step:  1\n",
      "loss:  0.0013153024483472109\n",
      "loss:  0.0011773802107200027\n",
      "loss:  0.0010983558604493737\n",
      "loss:  0.0010599689558148384\n",
      "loss:  0.000989444786682725\n",
      "loss:  0.0007088877027854323\n",
      "loss:  0.0005417756037786603\n",
      "loss:  0.0005243596970103681\n",
      "loss:  0.000507023767568171\n",
      "loss:  0.00047413029824383557\n",
      "loss:  0.00042707796092145145\n",
      "loss:  0.00034459971357136965\n",
      "loss:  0.0002317671023774892\n",
      "loss:  0.0001927754929056391\n",
      "loss:  0.00017632768140174448\n",
      "loss:  0.0001682182337390259\n",
      "loss:  0.00016535444592591375\n",
      "loss:  0.00016288537881337106\n",
      "loss:  0.00016262996359728277\n",
      "loss:  0.00016219241661019623\n",
      "Test Loss:  0.00018710840959101915\n",
      "n:  999\n",
      "Step:  2\n",
      "loss:  0.0001612520427443087\n",
      "loss:  0.00015911213995423168\n",
      "loss:  0.00015461027214769274\n",
      "loss:  0.00014668812218587846\n",
      "loss:  0.00013645549188368022\n",
      "loss:  0.00012550920655485243\n",
      "loss:  0.00011690346582327038\n",
      "loss:  0.00011349767737556249\n",
      "loss:  0.00011251460819039494\n",
      "loss:  0.00011226619244553149\n",
      "loss:  0.00011131195788038895\n",
      "loss:  9.977974696084857e-05\n",
      "loss:  8.716657612239942e-05\n",
      "loss:  7.965604163473472e-05\n",
      "loss:  7.765284681227058e-05\n",
      "loss:  7.737447594990954e-05\n",
      "loss:  7.527843990828842e-05\n",
      "loss:  7.46831065043807e-05\n",
      "loss:  7.379557064268738e-05\n",
      "loss:  7.296952389879152e-05\n",
      "Test Loss:  0.00012049588985973969\n",
      "n:  999\n",
      "Step:  3\n",
      "loss:  7.268128683790565e-05\n",
      "loss:  7.23425328033045e-05\n",
      "loss:  7.213310891529545e-05\n",
      "loss:  7.191377517301589e-05\n",
      "loss:  7.153875776566565e-05\n",
      "loss:  7.097014895407483e-05\n",
      "loss:  7.035029557300732e-05\n",
      "loss:  6.945568020455539e-05\n",
      "loss:  6.800901610404253e-05\n",
      "loss:  6.570759433088824e-05\n",
      "loss:  6.224024400580674e-05\n",
      "loss:  5.6035212764982134e-05\n",
      "loss:  4.8273184802383184e-05\n",
      "loss:  4.413779970491305e-05\n",
      "loss:  4.02102195948828e-05\n",
      "loss:  3.9028138417052105e-05\n",
      "loss:  3.83925398637075e-05\n",
      "loss:  3.8085323467385024e-05\n",
      "loss:  3.7952137063257396e-05\n",
      "loss:  3.784777072723955e-05\n",
      "Test Loss:  4.854199505643919e-05\n",
      "n:  999\n",
      "Step:  4\n",
      "loss:  3.7687535950681195e-05\n",
      "loss:  3.738989835255779e-05\n",
      "loss:  3.683944305521436e-05\n",
      "loss:  3.5868713894160464e-05\n",
      "loss:  3.4323613363085315e-05\n",
      "loss:  3.646559707704e-05\n",
      "loss:  3.0321711165015586e-05\n",
      "loss:  2.8621712772292085e-05\n",
      "loss:  2.6134950530831702e-05\n",
      "loss:  2.451911313983146e-05\n",
      "loss:  2.3134354705689475e-05\n",
      "loss:  2.282047898916062e-05\n",
      "loss:  2.258805398014374e-05\n",
      "loss:  2.246902477054391e-05\n",
      "loss:  2.239754940092098e-05\n",
      "loss:  2.234875864814967e-05\n",
      "loss:  2.2318043193081394e-05\n",
      "loss:  2.2292753783403896e-05\n",
      "loss:  2.2260337573243305e-05\n",
      "loss:  2.2186759451869875e-05\n",
      "Test Loss:  2.357421544729732e-05\n",
      "n:  999\n",
      "Step:  5\n",
      "loss:  2.204430893470999e-05\n",
      "loss:  2.1732383174821734e-05\n",
      "loss:  2.1088402718305588e-05\n",
      "loss:  2.003225381486118e-05\n",
      "loss:  1.899158269225154e-05\n",
      "loss:  3.126261071884073e-05\n",
      "loss:  1.9081182472291403e-05\n",
      "loss:  2.5879971872200258e-05\n",
      "loss:  1.883717231976334e-05\n",
      "loss:  1.6866630176082253e-05\n",
      "loss:  1.4301874216471333e-05\n",
      "loss:  1.3771378689853009e-05\n",
      "loss:  1.2857388355769217e-05\n",
      "loss:  1.2355837498034816e-05\n",
      "loss:  1.2198071090097073e-05\n",
      "loss:  1.21482735266909e-05\n",
      "loss:  1.212472216138849e-05\n",
      "loss:  1.2103295375709422e-05\n",
      "loss:  1.208251342177391e-05\n",
      "loss:  1.203968349727802e-05\n",
      "Test Loss:  1.6726344256312586e-05\n",
      "n:  999\n",
      "Step:  6\n",
      "loss:  1.198564041260397e-05\n",
      "loss:  1.1895893294422422e-05\n",
      "loss:  1.1730446203728206e-05\n",
      "loss:  1.1467742297099903e-05\n",
      "loss:  1.1088735845987685e-05\n",
      "loss:  1.060263912222581e-05\n",
      "loss:  1.0578617548162583e-05\n",
      "loss:  9.954890629160218e-06\n",
      "loss:  9.811650670599192e-06\n",
      "loss:  9.654507266532164e-06\n",
      "loss:  9.326528925157618e-06\n",
      "loss:  9.068427971214987e-06\n",
      "loss:  8.80837887962116e-06\n",
      "loss:  8.751137102080975e-06\n",
      "loss:  8.436261850874871e-06\n",
      "loss:  8.302392416226212e-06\n",
      "loss:  8.121804967231583e-06\n",
      "loss:  8.023281225177925e-06\n",
      "loss:  7.92857554188231e-06\n",
      "loss:  7.772296157781966e-06\n",
      "Test Loss:  7.192677458078833e-06\n",
      "n:  999\n",
      "Step:  7\n",
      "loss:  7.718919732724316e-06\n",
      "loss:  7.598756383231375e-06\n",
      "loss:  7.566588465124369e-06\n",
      "loss:  7.511913736379938e-06\n",
      "loss:  7.408127203234471e-06\n",
      "loss:  7.307346095331013e-06\n",
      "loss:  7.21680680726422e-06\n",
      "loss:  7.073442702676402e-06\n",
      "loss:  6.8063395701756235e-06\n",
      "loss:  6.736593604728114e-06\n",
      "loss:  6.678373210888822e-06\n",
      "loss:  6.5983554122794885e-06\n",
      "loss:  6.551909336849349e-06\n",
      "loss:  6.524866876134183e-06\n",
      "loss:  6.4833066062419675e-06\n",
      "loss:  6.4710225160524715e-06\n",
      "loss:  6.459318228735356e-06\n",
      "loss:  6.45254885967006e-06\n",
      "loss:  6.450618457165547e-06\n",
      "loss:  6.449965439969674e-06\n",
      "Test Loss:  4.379282472655177e-06\n",
      "n:  999\n",
      "Step:  8\n",
      "loss:  6.449965439969674e-06\n",
      "Test Loss:  4.379282472655177e-06\n",
      "n:  999\n",
      "Step:  9\n",
      "loss:  6.449965439969674e-06\n",
      "Test Loss:  4.379282472655177e-06\n",
      "n:  999\n"
     ]
    }
   ],
   "source": [
    "# Initializing training steps\n",
    "trg_steps = 10\n",
    "\n",
    "for i in range (trg_steps):\n",
    "    print(\"Step: \", i)\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_input)\n",
    "        loss = criterion(out, train_target)\n",
    "        print(\"loss: \", loss.item())\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    optimizer.step(closure)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        future = 1000\n",
    "        # Pred includes future values \n",
    "        pred = model(test_input, prediction_window=future)\n",
    "        loss = criterion(pred[:, :-future], test_target)\n",
    "        print(\"Test Loss: \", loss.item())\n",
    "        y = pred.detach().numpy()\n",
    "        n = train_input.shape[1]\n",
    "\n",
    "        # print(\"Pred: \", pred)\n",
    "        # print(\"y: \", y[0])\n",
    "        # print(\"n: \", n)\n",
    "        # print(\"y_i[:n]: \", y[0][:n])\n",
    "        # print(\"y_i[n:]: \", y[0][n:])\n",
    "        \n",
    "        # print(\"History: \", y[:-future])\n",
    "        # print(\"Future: \", y[future:])\n",
    "\n",
    "    # # draw the result\n",
    "    # plt.figure(figsize=(30, 10))\n",
    "    # plt.title(\n",
    "    #     'Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "    # plt.xlabel('x', fontsize=20)\n",
    "    # plt.ylabel('y', fontsize=20)\n",
    "    # plt.xticks(fontsize=20)\n",
    "    # plt.yticks(fontsize=20)\n",
    "\n",
    "    # def draw(yi, color):\n",
    "    #     plt.plot(np.arange(train_input.size(1)),\n",
    "    #                 yi[:train_input.size(1)], color, linewidth=2.0)\n",
    "    #     plt.plot(np.arange(train_input.size(1), train_input.size(1) + future),\n",
    "    #                 yi[train_input.size(1):], color + ':', linewidth=2.0)\n",
    "    # draw(y[0], 'r')\n",
    "    # draw(y[1], 'g')\n",
    "    # draw(y[2], 'b')\n",
    "    # plt.savefig('predict%d.pdf' % i)\n",
    "    # plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.title(f\"Step {i+1}\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    n = train_input.shape[1] # 999\n",
    "    print(\"n: \", n)\n",
    "    def draw(y_i, color):\n",
    "        plt.plot(np.arange(n), y_i[:n], color, linewidth=2.0)\n",
    "        plt.plot(np.arange(n, n+future), y_i[n:], color + \":\", linewidth=2.0)\n",
    "        # print(\"y_i[:n]: \", y_i[:n])\n",
    "        # print(\"y_i[n:]: \", y_i[n:])\n",
    "\n",
    "\n",
    "    draw(y[0], 'r')\n",
    "    draw(y[1], 'g')\n",
    "    draw(y[2], 'b')\n",
    "\n",
    "    plt.savefig(\"predict%d.pdf\"%i)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netpred-kernel",
   "language": "python",
   "name": "netpred-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
